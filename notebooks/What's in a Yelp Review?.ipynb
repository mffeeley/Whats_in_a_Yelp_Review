{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's in a Yelp Review?\n",
    "**Michael Feeley**  \n",
    "**Metis Bootcamp - Project 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**===================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below are all the imported packages for this project.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obligatory\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Pre-processing\n",
    "import langdetect\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn.feature_extraction import text\n",
    "import string\n",
    "\n",
    "# Modeling\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data is stored in the 'data' subdirectory as json files.  Here, I use pandas' 'read_json' function to read in the data.**\n",
    "\n",
    "**The original review file was WAY too large to import on my Macbook.  I created a subset using terminal of the first 100K rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:32.421725Z",
     "start_time": "2020-01-08T03:38:26.753214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the reviews and business data\n",
    "review_df = pd.read_json(r'data/review_sub.json', lines = True)\n",
    "business_df = pd.read_json(r'data/business.json', lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I then chcked what features are in the review dataframe.  This will help determine what is actually useful for the project.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:35.330996Z",
     "start_time": "2020-01-08T03:38:35.327497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'cool', 'date', 'funny', 'review_id', 'stars', 'text',\n",
       "       'useful', 'user_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column names - review\n",
    "review_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I don't need most of these features for the purpose of this project, so I only kept:**\n",
    "* business_id (for zoning in on a categorical or views)\n",
    "* stars for the review (for analyzing positive and negative reviews separately)\n",
    "* text (for insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:35.743367Z",
     "start_time": "2020-01-08T03:38:35.724659Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retreieve the desired features\n",
    "review_df = review_df.loc[:,['business_id','stars','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:36.021398Z",
     "start_time": "2020-01-08T03:38:36.014370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>5</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>5</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>5</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>1</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  stars  \\\n",
       "0  ujmEBvifdJM6h6RLv4wQIg      1   \n",
       "1  NZnhc2sEQy3RmzKTZnqtwQ      5   \n",
       "2  WTqjgwHlXbSFevF32_DJVw      5   \n",
       "3  ikCg8xy5JIg_NGPx-MSIDA      5   \n",
       "4  b1b1eb3uo-w561D0ZfCEiQ      1   \n",
       "\n",
       "                                                text  \n",
       "0  Total bill for this horrible service? Over $8G...  \n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...  \n",
       "2  I have to say that this office really has it t...  \n",
       "3  Went in for a lunch. Steak sandwich was delici...  \n",
       "4  Today was my second out of three sessions I ha...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I did the same thing for the business dataframe, as I only needed the categories.  I also kept the cities for future work.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:36.290578Z",
     "start_time": "2020-01-08T03:38:36.287054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['address', 'attributes', 'business_id', 'categories', 'city', 'hours',\n",
       "       'is_open', 'latitude', 'longitude', 'name', 'postal_code',\n",
       "       'review_count', 'stars', 'state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column names - business\n",
    "business_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:36.890741Z",
     "start_time": "2020-01-08T03:38:36.586842Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the desired features\n",
    "business_df = business_df.loc[:,['business_id','categories','city']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:36.920209Z",
     "start_time": "2020-01-08T03:38:36.912471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1SWheh84yJXfytovILXOAQ</td>\n",
       "      <td>Golf, Active Life</td>\n",
       "      <td>Phoenix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Specialty Food, Restaurants, Dim Sum, Imported...</td>\n",
       "      <td>Mississauga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gnKjwL_1w79qoiV3IC_xQQ</td>\n",
       "      <td>Sushi Bars, Restaurants, Japanese</td>\n",
       "      <td>Charlotte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xvX2CttrVhyG2z1dFg_0xw</td>\n",
       "      <td>Insurance, Financial Services</td>\n",
       "      <td>Goodyear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HhyxOkGAM07SRYtlQ4wMFQ</td>\n",
       "      <td>Plumbing, Shopping, Local Services, Home Servi...</td>\n",
       "      <td>Charlotte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                         categories  \\\n",
       "0  1SWheh84yJXfytovILXOAQ                                  Golf, Active Life   \n",
       "1  QXAEGFB4oINsVuTFxEYKFQ  Specialty Food, Restaurants, Dim Sum, Imported...   \n",
       "2  gnKjwL_1w79qoiV3IC_xQQ                  Sushi Bars, Restaurants, Japanese   \n",
       "3  xvX2CttrVhyG2z1dFg_0xw                      Insurance, Financial Services   \n",
       "4  HhyxOkGAM07SRYtlQ4wMFQ  Plumbing, Shopping, Local Services, Home Servi...   \n",
       "\n",
       "          city  \n",
       "0      Phoenix  \n",
       "1  Mississauga  \n",
       "2    Charlotte  \n",
       "3     Goodyear  \n",
       "4    Charlotte  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display\n",
    "business_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here's where the two dataframes tie together.  I merged both dataframes on the business_id, then filtered the review dataframe to include only 'Food' or 'Restaurant' categories.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:37.446658Z",
     "start_time": "2020-01-08T03:38:37.234116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the dataframes\n",
    "review_df = review_df.merge(business_df, on = 'business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:37.555957Z",
     "start_time": "2020-01-08T03:38:37.544548Z"
    }
   },
   "outputs": [],
   "source": [
    "# All categories to be extracted\n",
    "food = [ \\\n",
    "     \"Afghan\", \"African\", \"Senegalese\", \"South African\", \"American (New)\", \n",
    "     \"American (Traditional)\", \"Arabian\", \"Argentine\", \"Armenian\", \"Asian Fusion\", \n",
    "     \"Australian\", \"Austrian\", \"Bangladeshi\", \"Barbeque\", \"Basque\", \"Belgian\", \n",
    "     \"Brasseries\", \"Brazilian\", \"Breakfast & Brunch\", \"British\", \"Buffets\", \n",
    "     \"Burgers\", \"Burmese\", \"Cafes\", \"Themed Cafes\", \"Cafeteria\", \"Cajun/Creole\", \n",
    "     \"Cambodian\", \"Caribbean\", \"Dominican\", \"Haitian\", \"Puerto Rican\", \"Trinidadian\", \n",
    "     \"Catalan\", \"Cheesesteaks\", \"Chicken Shop\", \"Chicken Wings\", \"Chinese\", \"Cantonese\", \n",
    "     \"Dim Sum\", \"Hainan\", \"Shanghainese\", \"Szechuan\", \"Comfort Food\", \"Creperies\", \n",
    "     \"Cuban\", \"Czech\", \"Delis\", \"Diners\", \"Dinner Theater\", \"Ethiopian\", \"Fast Food\", \n",
    "     \"Filipino\", \"Fish & Chips\", \"Fondue\", \"Food Court\", \"Food Stands\", \"French\", \n",
    "     \"Mauritius\", \"Reunion\", \"Game Meat\", \"Gastropubs\", \"German\", \"Gluten-Free\", \"Greek\", \n",
    "     \"Guamanian\", \"Halal\", \"Hawaiian\", \"Himalayan/Nepalese\", \"Honduran\", \n",
    "     \"Hong Kong Style Cafe\", \"Hot Dogs\", \"Hot Pot\", \"Hungarian\", \"Iberian\", \"Indian\", \n",
    "     \"Indonesian\", \"Irish\", \"Italian\", \"Calabrian\", \"Sardinian\", \"Sicilian\", \"Tuscan\", \n",
    "     \"Japanese\", \"Conveyor Belt Sushi\", \"Izakaya\", \"Japanese Curry\", \"Ramen\", \n",
    "     \"Teppanyaki\", \"Kebab\", \"Korean\", \"Kosher\", \"Laotian\", \"Latin American\", \"Colombian\", \n",
    "     \"Salvadoran\", \"Venezuelan\", \"Live/Raw Food\", \"Malaysian\", \"Mediterranean\", \"Falafel\", \n",
    "     \"Mexican\", \"Tacos\", \"Middle Eastern\", \"Egyptian\", \"Lebanese\", \"Modern European\", \n",
    "     \"Mongolian\", \"Moroccan\", \"New Mexican Cuisine\", \"Nicaraguan\", \"Noodles\", \"Pakistani\",\n",
    "     \"Pan Asia\", \"Persian/Iranian\", \"Peruvian\", \"Pizza\", \"Polish\", \"Polynesian\", \n",
    "     \"Pop-Up Restaurants\", \"Portuguese\", \"Poutineries\", \"Russian\", \"Salad\", \"Sandwiches\", \n",
    "     \"Scandinavian\", \"Scottish\", \"Seafood\", \"Singaporean\", \"Slovakian\", \"Soul Food\", \"Soup\", \n",
    "     \"Southern\", \"Spanish\", \"Sri Lankan\", \"Steakhouses\", \"Supper Clubs\", \"Sushi Bars\", \n",
    "     \"Syrian\", \"Taiwanese\", \"Tapas Bars\", \"Tapas/Small Plates\", \"Tex-Mex\", \"Thai\", \n",
    "     \"Turkish\", \"Ukrainian\", \"Uzbek\", \"Vegan\", \"Vegetarian\", \"Vietnamese\", \"Waffles\", \"Wraps\",\n",
    "     \"Food\", \"Bakeries\", \"Acai Bowls\", \"Bagels\", \"Bakeries\", \"Beer, Wine & Spirits\", \"Beverage Store\", \n",
    "     \"Breweries\", \"Brewpubs\", \"Bubble Tea\", \"Butcher\", \"CSA\", \"Chimney Cakes\", \"Cideries\", \n",
    "     \"Coffee & Tea\", \"Coffee Roasteries\", \"Convenience Stores\", \"Cupcakes\", \"Custom Cakes\", \n",
    "     \"Desserts\", \"Distilleries\", \"Do-It-Yourself Food\", \"Donuts\", \"Empanadas\", \"Farmers Market\", \n",
    "     \"Food Delivery Services\", \"Food Trucks\", \"Gelato\", \"Grocery\", \"Honey\", \"Ice Cream & Frozen Yogurt\", \n",
    "     \"Imported Food\", \"International Grocery\", \"Internet Cafes\", \"Juice Bars & Smoothies\", \"Kombucha\", \n",
    "     \"Organic Stores\", \"Patisserie/Cake Shop\", \"Piadina\", \"Poke\", \"Pretzels\", \"Shaved Ice\", \"Shaved Snow\", \n",
    "     \"Smokehouse\", \"Specialty Food\", \"Candy Stores\", \"Cheese Shops\", \"Chocolatiers & Shops\", \n",
    "     \"Fruits & Veggies\", \"Health Markets\", \"Herbs & Spices\", \"Macarons\", \"Meat Shops\", \"Olive Oil\", \"Pasta Shops\", \n",
    "     \"Popcorn Shops\", \"Seafood Markets\", \"Street Vendors\", \"Tea Rooms\", \"Water Stores\", \"Wineries\", \"Wine Tasting Room\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:38.426145Z",
     "start_time": "2020-01-08T03:38:37.873948Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>[Fitness &amp; Instruction, Doctors, Health &amp; Medi...</td>\n",
       "      <td>Las Vegas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>4</td>\n",
       "      <td>My family has used this ER four times in the p...</td>\n",
       "      <td>[Fitness &amp; Instruction, Doctors, Health &amp; Medi...</td>\n",
       "      <td>Las Vegas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1</td>\n",
       "      <td>I have never been more disappointed by the car...</td>\n",
       "      <td>[Fitness &amp; Instruction, Doctors, Health &amp; Medi...</td>\n",
       "      <td>Las Vegas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1</td>\n",
       "      <td>Went in for a broken finger, was asked if I wa...</td>\n",
       "      <td>[Fitness &amp; Instruction, Doctors, Health &amp; Medi...</td>\n",
       "      <td>Las Vegas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>5</td>\n",
       "      <td>My mother was at Mountain View for nearly two ...</td>\n",
       "      <td>[Fitness &amp; Instruction, Doctors, Health &amp; Medi...</td>\n",
       "      <td>Las Vegas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  stars  \\\n",
       "0  ujmEBvifdJM6h6RLv4wQIg      1   \n",
       "1  ujmEBvifdJM6h6RLv4wQIg      4   \n",
       "2  ujmEBvifdJM6h6RLv4wQIg      1   \n",
       "3  ujmEBvifdJM6h6RLv4wQIg      1   \n",
       "4  ujmEBvifdJM6h6RLv4wQIg      5   \n",
       "\n",
       "                                                text  \\\n",
       "0  Total bill for this horrible service? Over $8G...   \n",
       "1  My family has used this ER four times in the p...   \n",
       "2  I have never been more disappointed by the car...   \n",
       "3  Went in for a broken finger, was asked if I wa...   \n",
       "4  My mother was at Mountain View for nearly two ...   \n",
       "\n",
       "                                          categories       city  \n",
       "0  [Fitness & Instruction, Doctors, Health & Medi...  Las Vegas  \n",
       "1  [Fitness & Instruction, Doctors, Health & Medi...  Las Vegas  \n",
       "2  [Fitness & Instruction, Doctors, Health & Medi...  Las Vegas  \n",
       "3  [Fitness & Instruction, Doctors, Health & Medi...  Las Vegas  \n",
       "4  [Fitness & Instruction, Doctors, Health & Medi...  Las Vegas  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the categories feature in a list\n",
    "review_df['categories'] = review_df['categories'].apply(lambda x: str(x).split(','))\n",
    "\n",
    "# Strip white space\n",
    "review_df['categories'] = review_df['categories'].apply(lambda x: [cat.strip() for cat in x])\n",
    "\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:39.305986Z",
     "start_time": "2020-01-08T03:38:38.428692Z"
    }
   },
   "outputs": [],
   "source": [
    "# Flag the document for whether it's in relevant categories\n",
    "review_df['food'] = review_df['categories'].apply(lambda x: [set(x) & set(food)])\n",
    "review_df['food'] = review_df['food'].apply(lambda x: len(x[0]) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:39.391689Z",
     "start_time": "2020-01-08T03:38:39.308715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve desires observations (only food reviews)\n",
    "review_df = review_df[review_df['food'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:39.408372Z",
     "start_time": "2020-01-08T03:38:39.394630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>5</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>[Bars, Pubs, Nightlife, Tapas Bars, Restaurants]</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>1</td>\n",
       "      <td>Really one of dirtiest places to eat,not sure ...</td>\n",
       "      <td>[Bars, Pubs, Nightlife, Tapas Bars, Restaurants]</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>1</td>\n",
       "      <td>Terrible place to eat and or drink, waitresses...</td>\n",
       "      <td>[Bars, Pubs, Nightlife, Tapas Bars, Restaurants]</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>eU_713ec6fTGNO4BegRaww</td>\n",
       "      <td>4</td>\n",
       "      <td>I'll be the first to admit that I was not exci...</td>\n",
       "      <td>[Restaurants, Italian, Pizza]</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>eU_713ec6fTGNO4BegRaww</td>\n",
       "      <td>5</td>\n",
       "      <td>One of the best Italian restaurants in a city ...</td>\n",
       "      <td>[Restaurants, Italian, Pizza]</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id  stars  \\\n",
       "60  ikCg8xy5JIg_NGPx-MSIDA      5   \n",
       "61  ikCg8xy5JIg_NGPx-MSIDA      1   \n",
       "62  ikCg8xy5JIg_NGPx-MSIDA      1   \n",
       "75  eU_713ec6fTGNO4BegRaww      4   \n",
       "76  eU_713ec6fTGNO4BegRaww      5   \n",
       "\n",
       "                                                 text  \\\n",
       "60  Went in for a lunch. Steak sandwich was delici...   \n",
       "61  Really one of dirtiest places to eat,not sure ...   \n",
       "62  Terrible place to eat and or drink, waitresses...   \n",
       "75  I'll be the first to admit that I was not exci...   \n",
       "76  One of the best Italian restaurants in a city ...   \n",
       "\n",
       "                                          categories        city  food  \n",
       "60  [Bars, Pubs, Nightlife, Tapas Bars, Restaurants]     Calgary  True  \n",
       "61  [Bars, Pubs, Nightlife, Tapas Bars, Restaurants]     Calgary  True  \n",
       "62  [Bars, Pubs, Nightlife, Tapas Bars, Restaurants]     Calgary  True  \n",
       "75                     [Restaurants, Italian, Pizza]  Pittsburgh  True  \n",
       "76                     [Restaurants, Italian, Pizza]  Pittsburgh  True  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When exploring the data, I noticed some foreign languages.  Since I'm only working with English, I used the 'langdetect' package to detect which reviews are in English and filtered down the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:38:39.446334Z",
     "start_time": "2020-01-08T03:38:39.442925Z"
    }
   },
   "outputs": [],
   "source": [
    "def language(x):\n",
    "    '''\n",
    "    Detect the language of a string.\n",
    "    '''\n",
    "    try:\n",
    "        return langdetect.detect(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:42:47.011572Z",
     "start_time": "2020-01-08T03:38:39.781298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Language flag\n",
    "review_df['language'] = review_df['text'].apply(lambda x: language(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The dataset now has a language feature, which I will use to take an English-only subset of the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:42:47.029812Z",
     "start_time": "2020-01-08T03:42:47.014874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>food</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>5</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>[Bars, Pubs, Nightlife, Tapas Bars, Restaurants]</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>1</td>\n",
       "      <td>Really one of dirtiest places to eat,not sure ...</td>\n",
       "      <td>[Bars, Pubs, Nightlife, Tapas Bars, Restaurants]</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>1</td>\n",
       "      <td>Terrible place to eat and or drink, waitresses...</td>\n",
       "      <td>[Bars, Pubs, Nightlife, Tapas Bars, Restaurants]</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>eU_713ec6fTGNO4BegRaww</td>\n",
       "      <td>4</td>\n",
       "      <td>I'll be the first to admit that I was not exci...</td>\n",
       "      <td>[Restaurants, Italian, Pizza]</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>eU_713ec6fTGNO4BegRaww</td>\n",
       "      <td>5</td>\n",
       "      <td>One of the best Italian restaurants in a city ...</td>\n",
       "      <td>[Restaurants, Italian, Pizza]</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id  stars  \\\n",
       "60  ikCg8xy5JIg_NGPx-MSIDA      5   \n",
       "61  ikCg8xy5JIg_NGPx-MSIDA      1   \n",
       "62  ikCg8xy5JIg_NGPx-MSIDA      1   \n",
       "75  eU_713ec6fTGNO4BegRaww      4   \n",
       "76  eU_713ec6fTGNO4BegRaww      5   \n",
       "\n",
       "                                                 text  \\\n",
       "60  Went in for a lunch. Steak sandwich was delici...   \n",
       "61  Really one of dirtiest places to eat,not sure ...   \n",
       "62  Terrible place to eat and or drink, waitresses...   \n",
       "75  I'll be the first to admit that I was not exci...   \n",
       "76  One of the best Italian restaurants in a city ...   \n",
       "\n",
       "                                          categories        city  food  \\\n",
       "60  [Bars, Pubs, Nightlife, Tapas Bars, Restaurants]     Calgary  True   \n",
       "61  [Bars, Pubs, Nightlife, Tapas Bars, Restaurants]     Calgary  True   \n",
       "62  [Bars, Pubs, Nightlife, Tapas Bars, Restaurants]     Calgary  True   \n",
       "75                     [Restaurants, Italian, Pizza]  Pittsburgh  True   \n",
       "76                     [Restaurants, Italian, Pizza]  Pittsburgh  True   \n",
       "\n",
       "   language  \n",
       "60       en  \n",
       "61       en  \n",
       "62       en  \n",
       "75       en  \n",
       "76       en  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:42:47.047156Z",
     "start_time": "2020-01-08T03:42:47.033144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en       67030\n",
       "fr         336\n",
       "es          23\n",
       "de          17\n",
       "zh-cn        8\n",
       "it           7\n",
       "ja           4\n",
       "nl           4\n",
       "pt           3\n",
       "sk           3\n",
       "da           3\n",
       "zh-tw        2\n",
       "no           2\n",
       "cy           2\n",
       "ca           1\n",
       "af           1\n",
       "tl           1\n",
       "hr           1\n",
       "ko           1\n",
       "ro           1\n",
       "fi           1\n",
       "sv           1\n",
       "sl           1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Language distribution\n",
    "review_df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:42:47.131909Z",
     "start_time": "2020-01-08T03:42:47.049596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Only include English\n",
    "review_df = review_df[review_df['language'] == 'en'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is where the text pre-processing begins.  I removed all punctuation marks and numbers, and made all letters lowercase.  I also removed the new line (\\n) character from all reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:42:47.141277Z",
     "start_time": "2020-01-08T03:42:47.134133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Really one of dirtiest places to eat,not sure how they get past the Health inspections,very rude staff and management. Spend your money elsewhere.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample raw text\n",
    "review_df['text'][1][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T03:42:52.043609Z",
     "start_time": "2020-01-08T03:42:47.143354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>food</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>5</td>\n",
       "      <td>went in for a lunch  steak sandwich was delici...</td>\n",
       "      <td>[Bars, Pubs, Nightlife, Tapas Bars, Restaurants]</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>1</td>\n",
       "      <td>really one of dirtiest places to eat not sure ...</td>\n",
       "      <td>[Bars, Pubs, Nightlife, Tapas Bars, Restaurants]</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>1</td>\n",
       "      <td>terrible place to eat and or drink  waitresses...</td>\n",
       "      <td>[Bars, Pubs, Nightlife, Tapas Bars, Restaurants]</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eU_713ec6fTGNO4BegRaww</td>\n",
       "      <td>4</td>\n",
       "      <td>ill be the first to admit that i was not excit...</td>\n",
       "      <td>[Restaurants, Italian, Pizza]</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eU_713ec6fTGNO4BegRaww</td>\n",
       "      <td>5</td>\n",
       "      <td>one of the best italian restaurants in a city ...</td>\n",
       "      <td>[Restaurants, Italian, Pizza]</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  stars  \\\n",
       "0  ikCg8xy5JIg_NGPx-MSIDA      5   \n",
       "1  ikCg8xy5JIg_NGPx-MSIDA      1   \n",
       "2  ikCg8xy5JIg_NGPx-MSIDA      1   \n",
       "3  eU_713ec6fTGNO4BegRaww      4   \n",
       "4  eU_713ec6fTGNO4BegRaww      5   \n",
       "\n",
       "                                                text  \\\n",
       "0  went in for a lunch  steak sandwich was delici...   \n",
       "1  really one of dirtiest places to eat not sure ...   \n",
       "2  terrible place to eat and or drink  waitresses...   \n",
       "3  ill be the first to admit that i was not excit...   \n",
       "4  one of the best italian restaurants in a city ...   \n",
       "\n",
       "                                         categories        city  food language  \n",
       "0  [Bars, Pubs, Nightlife, Tapas Bars, Restaurants]     Calgary  True       en  \n",
       "1  [Bars, Pubs, Nightlife, Tapas Bars, Restaurants]     Calgary  True       en  \n",
       "2  [Bars, Pubs, Nightlife, Tapas Bars, Restaurants]     Calgary  True       en  \n",
       "3                     [Restaurants, Italian, Pizza]  Pittsburgh  True       en  \n",
       "4                     [Restaurants, Italian, Pizza]  Pittsburgh  True       en  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the apostrophes (separation issues in word_tokenize)\n",
    "remove_apostrophes = lambda x: x.replace('\\'', '')\n",
    "\n",
    "# Keep only letters\n",
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "\n",
    "# Make them lowercase\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "# Remove new line characters\n",
    "no_new_line = lambda x: x.replace('\\n','')\n",
    "\n",
    "review_df['text'] = review_df['text'].map(remove_apostrophes).map(alphanumeric).map(punc_lower).map(no_new_line)\n",
    "review_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this point, I pickled the dataframe to save the work done so far and load it back up quickly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T05:11:37.055768Z",
     "start_time": "2020-01-08T05:11:36.845156Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('pickles/review_df','wb') as file:\n",
    "      pickle.dump(review_df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As is typical with NLP projects, I applied lemmatization to the text.  First, I wrote a function to get the part of speech based on the 'nltk.pos_tag' function.  I passed this value into the lemmatizer function to get the accurately stemmed version of the word (this wasn't 100% accurate, but more accurate than without the part-of-speech tag.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T05:18:24.483133Z",
     "start_time": "2020-01-08T05:18:24.479247Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    '''\n",
    "    Map POS tag to first character lemmatize() accepts.\n",
    "    '''\n",
    "    \n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T05:20:08.355545Z",
     "start_time": "2020-01-08T05:20:08.351833Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    '''\n",
    "    Lemmatize a given string.\n",
    "    '''\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in word_tokenize(text)]\n",
    "    lemmatized_text = ' '.join(tokens)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T05:35:45.962710Z",
     "start_time": "2020-01-08T05:22:59.283542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply lemmatization to the text\n",
    "review_df['text'] = review_df['text'].apply(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**===================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is my favorite part of text pre-processing!  'Stop words' are words that don't add much value to the data.  For example, 'the', 'her', 'town', 'then' are all useless words that add unneccessary noise to the data.  As you add more stop words, you'll notice the topics that we model after vectorization become more specific.  If you add too many, you may end up 'overfitting' the topic.  If you don't have enough, you may not have distinguishable topics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the main list of stop words taken from the nltk and sklearn stop word lists.  I removed apostrophes so it'll match the punctuation mark-less text from my dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T15:46:19.499345Z",
     "start_time": "2020-01-08T15:46:19.495450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add general English stopwords without apostrophes\n",
    "nltk_stopwords = []\n",
    "\n",
    "for word in list(stopwords.words('english')):\n",
    "    nltk_stopwords.append(word.replace('\\'',''))\n",
    "\n",
    "# Add these words to our main list\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(nltk_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I then created an ongoing list of stop words to add as I honed in on specific topics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:08:58.080344Z",
     "start_time": "2020-01-08T16:08:58.075282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'about', 'above', 'across', 'after']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more stop words here\n",
    "add_stop_words = ['las','la','tony','ive','say','really','eat','friend','im','cup',\n",
    "                  'good','food']\n",
    "\n",
    "# Join the stop words above to the original list\n",
    "stop_words = stop_words.union(add_stop_words)\n",
    "\n",
    "# Display the first five alphabetically\n",
    "list(sorted(stop_words))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**===================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that the text has been cleaned, it's time to vectorize it.  Vectorization involves collecting every word that occurs in the entire dataset, and counting how many times it appear in each document.  I used the TfidfVectorizer from sklearn for this task.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T17:13:29.402140Z",
     "start_time": "2020-01-08T17:13:25.692813Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the vectorizer object\n",
    "vectorizer = TfidfVectorizer(stop_words = stop_words, min_df = .005)\n",
    "\n",
    "# Create the doc_word sprase matrix\n",
    "doc_word = vectorizer.fit_transform(review_df['text'])\n",
    "\n",
    "# Create a dataframe for easy labeled viewing\n",
    "doc_word_df = pd.DataFrame(doc_word.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here you can see the result of vectorization.  Because many words only appear in a small number of reviews, the matrix contains a large number of zeros.  This is known as a 'sparse matrix'.  In the above code, the 'doc_word.tooaray()' function call takes the doc_word sparse matrix object and converts it into the content of the dataframe below (with the zeros included).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T21:31:04.222735Z",
     "start_time": "2020-01-08T21:31:04.199772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accommodate</th>\n",
       "      <th>act</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>addition</th>\n",
       "      <th>additional</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184802</td>\n",
       "      <td>0.223004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolute  absolutely  accommodate  act  actual  actually  add  \\\n",
       "0   0.0       0.0    0.184802     0.223004  0.0     0.0       0.0  0.0   \n",
       "1   0.0       0.0    0.000000     0.000000  0.0     0.0       0.0  0.0   \n",
       "2   0.0       0.0    0.000000     0.000000  0.0     0.0       0.0  0.0   \n",
       "3   0.0       0.0    0.000000     0.000000  0.0     0.0       0.0  0.0   \n",
       "4   0.0       0.0    0.000000     0.000000  0.0     0.0       0.0  0.0   \n",
       "\n",
       "   addition  additional  ...  yeah  year  yelp  yes  yesterday  yogurt  york  \\\n",
       "0       0.0         0.0  ...   0.0   0.0   0.0  0.0        0.0     0.0   0.0   \n",
       "1       0.0         0.0  ...   0.0   0.0   0.0  0.0        0.0     0.0   0.0   \n",
       "2       0.0         0.0  ...   0.0   0.0   0.0  0.0        0.0     0.0   0.0   \n",
       "3       0.0         0.0  ...   0.0   0.0   0.0  0.0        0.0     0.0   0.0   \n",
       "4       0.0         0.0  ...   0.0   0.0   0.0  0.0        0.0     0.0   0.0   \n",
       "\n",
       "   young  yum  yummy  \n",
       "0    0.0  0.0    0.0  \n",
       "1    0.0  0.0    0.0  \n",
       "2    0.0  0.0    0.0  \n",
       "3    0.0  0.0    0.0  \n",
       "4    0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 1164 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**===================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now have a matrix of review vectors that each contain a value for each word, AKA document_word matrix or document_term matrix.  With this, I can create an NMF topic model object (Non-negative Matrix Factorization) and fit it to my dataset.**\n",
    "\n",
    "**After experimenting with a variety of values for 'n_components' (the number of topics to cluster), I found 10 to be an optimal number for accurate and helpful topics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T19:31:31.547564Z",
     "start_time": "2020-01-08T19:31:25.601082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize NMF model with 10 topics\n",
    "nmf = NMF(n_components = 10)\n",
    "\n",
    "# Fit the doc_word sparse matrix\n",
    "doc_topic = nmf.fit_transform(doc_word)\n",
    "\n",
    "# Create a dataframe for easy labeled viewin\n",
    "doc_topic_df = pd.DataFrame(doc_topic.round(5),\n",
    "                            index = review_df.text.apply(lambda x: x[:100]),\n",
    "                            columns = range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The modeling process outputs a set of a matrix of review vectors, each containing a weight for each topic.  Because the computer cannot label the topics itself (it's clustering purely based on the review vectors, not actually separating topics) it's my job as a human to label the topics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T22:59:52.785003Z",
     "start_time": "2020-01-08T22:59:52.773900Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>go in for a lunch steak sandwich be delicious and the caesar salad have an absolutely delicious dres</th>\n",
       "      <td>0.00043</td>\n",
       "      <td>0.02337</td>\n",
       "      <td>0.00141</td>\n",
       "      <td>0.01143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          0        1        2  \\\n",
       "text                                                                            \n",
       "go in for a lunch steak sandwich be delicious a...  0.00043  0.02337  0.00141   \n",
       "\n",
       "                                                          3    4        5  \\\n",
       "text                                                                        \n",
       "go in for a lunch steak sandwich be delicious a...  0.01143  0.0  0.02099   \n",
       "\n",
       "                                                      6    7    8        9  \n",
       "text                                                                        \n",
       "go in for a lunch steak sandwich be delicious a...  0.0  0.0  0.0  0.02662  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The function below displays the top n words for each 'topic' found by the NMF model.  If the words make sense to be together and fall under a specific topic, the model did a good job of extracting a topic from the collection of reviews.  This ties back in to the goal of the project, which is to figure out what topics are associated with positive reviews and negative reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T21:58:37.816081Z",
     "start_time": "2020-01-08T21:58:37.811555Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic: \", ix)\n",
    "        else:\n",
    "            print(\"\\n\", ix+1, \"-\", topic_names[ix], \"\\n\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T21:58:47.583533Z",
     "start_time": "2020-01-08T21:58:47.577293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic:  0\n",
      "order, time, wait, come, minute, ask, table, service, drink, server, bad, customer, hour, waitress, told\n",
      "\n",
      "Topic:  1\n",
      "great, service, atmosphere, price, beer, selection, drink, awesome, bar, wine, spot, happy, nice, lunch, fun\n",
      "\n",
      "Topic:  2\n",
      "pizza, crust, cheese, topping, slice, sauce, order, wing, delivery, salad, pie, best, garlic, italian, dough\n",
      "\n",
      "Topic:  3\n",
      "chicken, fry, rice, order, sauce, dish, soup, salad, noodle, spicy, beef, thai, curry, pork, chinese\n",
      "\n",
      "Topic:  4\n",
      "burger, fry, cheese, beer, onion, bun, patty, ring, bacon, mac, shake, guy, joint, topping, dog\n",
      "\n",
      "Topic:  5\n",
      "like, try, taste, little, make, sandwich, nice, menu, coffee, look, cream, flavor, pretty, breakfast, ice\n",
      "\n",
      "Topic:  6\n",
      "sushi, roll, buffet, price, fresh, quality, fish, sashimi, lunch, crab, tuna, salmon, rice, las_vegas, best\n",
      "\n",
      "Topic:  7\n",
      "place, love, favorite, try, awesome, time, people, clean, fun, new, family, nice, recommend, look, year\n",
      "\n",
      "Topic:  8\n",
      "taco, salsa, mexican, fish, burrito, chip, asada, bean, tortilla, margarita, carne, guacamole, enchilada, meat, street\n",
      "\n",
      "Topic:  9\n",
      "amaze, friendly, staff, best, delicious, recommend, definitely, service, restaurant, highly, excellent, super, las_vegas, time, come\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf, vectorizer.get_feature_names(), 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can see in the above that the topics are fairly accurately clustered.  Topic 2 seems to be about pizzerias, topic 6 is about sushi or Japanese restaurants, and Topic 8 is about Mexican restaurants.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**===================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive vs Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I split the reviews into positive and negative subset to explore what words are associated with each sentiment.  I ran the same vectorization and modeling process on both subsets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start with positive reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:04:15.247701Z",
     "start_time": "2020-01-08T23:04:15.219823Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the mask for positive reviews (only 5 and 4 stars)\n",
    "pos_mask = ((review_df['stars'] == 5.0) |\n",
    "            (review_df['stars'] == 4.0))\n",
    "\n",
    "pos_review_df = review_df[pos_mask].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:06:21.184450Z",
     "start_time": "2020-01-08T23:06:18.836863Z"
    },
    "heading_collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the vectorizer object\n",
    "pos_vectorizer = TfidfVectorizer(stop_words = stop_words, min_df = .005)\n",
    "\n",
    "# Create the doc_word sprase matrix\n",
    "pos_doc_word = pos_vectorizer.fit_transform(pos_review_df['text'])\n",
    "\n",
    "# Create a dataframe for easy labeled viewing\n",
    "pos_doc_word_df = pd.DataFrame(pos_doc_word.toarray(), columns = pos_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:14:03.583760Z",
     "start_time": "2020-01-08T23:14:00.107906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize NMF model with 10 topics\n",
    "pos_nmf = NMF(n_components = 10)\n",
    "\n",
    "# Fit the doc_word sparse matrix\n",
    "pos_doc_topic = pos_nmf.fit_transform(pos_doc_word)\n",
    "\n",
    "# Create a dataframe for easy labeled viewin\n",
    "pos_doc_topic_df = pd.DataFrame(pos_doc_topic.round(5),\n",
    "                                index = pos_review_df.text.apply(lambda x: x[:100]),\n",
    "                                columns = range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then do the same for negative reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:55:54.929801Z",
     "start_time": "2020-01-08T23:55:54.916907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the mask for positive reviews (only 5 and 4 stars)\n",
    "neg_mask = ((review_df['stars'] == 2.0) |\n",
    "            (review_df['stars'] == 1.0))\n",
    "\n",
    "neg_review_df = review_df[neg_mask].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:55:56.431244Z",
     "start_time": "2020-01-08T23:55:55.335993Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the vectorizer object\n",
    "neg_vectorizer = TfidfVectorizer(stop_words = stop_words, min_df = .005)\n",
    "\n",
    "# Create the doc_word sprase matrix\n",
    "neg_doc_word = neg_vectorizer.fit_transform(neg_review_df['text'])\n",
    "\n",
    "# Create a dataframe for easy labeled viewing\n",
    "neg_doc_word_df = pd.DataFrame(neg_doc_word.toarray(), columns = neg_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:55:58.063260Z",
     "start_time": "2020-01-08T23:55:56.433634Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize NMF model with 10 topics\n",
    "neg_nmf = NMF(n_components = 10)\n",
    "\n",
    "# Fit the doc_word sparse matrix\n",
    "neg_doc_topic = neg_nmf.fit_transform(neg_doc_word)\n",
    "\n",
    "# Create a dataframe for easy labeled viewin\n",
    "neg_doc_topic_df = pd.DataFrame(neg_doc_topic.round(5),\n",
    "                                index = neg_review_df.text.apply(lambda x: x[:100]),\n",
    "                                columns = range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then compare the topics for positive and nevative reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T00:27:45.800916Z",
     "start_time": "2020-01-09T00:27:45.798343Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_topics = ['General','Experience','Pizzeria','Chinese Food','Positivity',\n",
    "              'Burger Joint','Sushi','Breakfast','Mexican Food','Experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T00:29:35.997470Z",
     "start_time": "2020-01-09T00:29:35.994852Z"
    }
   },
   "outputs": [],
   "source": [
    "neg_topics = ['General','Chinese Food','Pizzeria','Wait Time','Staff',\n",
    "              'Burger Joint','Service','Seafood','Sushi','Mexican Food']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When taking a closer look at top words extracted per topic, a number of insights are apparent.**\n",
    "* Pizzeria's typically get negative reviews for burnt or soggy pizza, and slow delivery.\n",
    "* Offering fresh sauce, and having plenty of garlic is key.\n",
    "* Wait time and staff attitude are big drivers of negative sentiment.\n",
    "* Burger joints needs to make sure they don't overcook their burgers.  Keep it fresh and juicy.\n",
    "* Also, serve the burgers in a timely manner, because 'cold' is a frequent term used in negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T00:30:50.126087Z",
     "start_time": "2020-01-09T00:30:50.118577Z"
    },
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 - General \n",
      "\n",
      "time, come, like, order, make, menu, wait, restaurant, drink, table, nice, bar, night, little, look\n",
      "\n",
      " 2 - Experience \n",
      "\n",
      "great, service, atmosphere, price, awesome, beer, selection, drink, customer, excellent, lunch, spot, fantastic, wine, fun\n",
      "\n",
      " 3 - Pizzeria \n",
      "\n",
      "pizza, crust, cheese, topping, slice, wing, sauce, order, salad, delivery, italian, best, pie, fresh, garlic\n",
      "\n",
      " 4 - Chinese Food \n",
      "\n",
      "chicken, fry, rice, order, sauce, soup, dish, salad, delicious, spicy, noodle, beef, thai, try, pork\n",
      "\n",
      " 5 - Positivity \n",
      "\n",
      "place, love, favorite, try, awesome, like, new, family, recommend, people, clean, fun, look, kid, time\n",
      "\n",
      " 6 - Burger Joint \n",
      "\n",
      "burger, fry, cheese, beer, onion, ring, mac, bacon, bun, patty, dog, juicy, shake, guy, joint\n",
      "\n",
      " 7 - Sushi \n",
      "\n",
      "amaze, best, sushi, service, recommend, highly, restaurant, las_vegas, roll, excellent, definitely, delicious, town, absolutely, customer\n",
      "\n",
      " 8 - Breakfast \n",
      "\n",
      "breakfast, coffee, sandwich, cream, ice, egg, chocolate, cake, flavor, delicious, tea, shop, toast, bagel, sweet\n",
      "\n",
      " 9 - Mexican Food \n",
      "\n",
      "taco, salsa, mexican, burrito, fish, chip, asada, margarita, carne, tortilla, bean, guacamole, street, al, authentic\n",
      "\n",
      " 10 - Experience \n",
      "\n",
      "staff, friendly, super, nice, clean, helpful, delicious, fast, location, atmosphere, price, fresh, attentive, quick, definitely\n"
     ]
    }
   ],
   "source": [
    "display_topics(pos_nmf, pos_vectorizer.get_feature_names(), 15, topic_names = pos_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T00:30:53.243711Z",
     "start_time": "2020-01-09T00:30:53.236562Z"
    },
    "cell_style": "split",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 - General \n",
      "\n",
      "table, come, server, ask, drink, waitress, seat, restaurant, bar, waiter, water, meal, menu, sat, manager\n",
      "\n",
      " 2 - Chinese Food \n",
      "\n",
      "chicken, sauce, order, taste, rice, fry, salad, like, dry, flavor, soup, sandwich, dish, meat, noodle\n",
      "\n",
      " 3 - Pizzeria \n",
      "\n",
      "pizza, crust, cheese, order, delivery, sauce, topping, slice, like, deliver, pie, dough, burnt, soggy, wing\n",
      "\n",
      " 4 - Wait Time \n",
      "\n",
      "wait, order, minute, hour, long, time, min, finally, line, told, later, busy, people, arrive, ready\n",
      "\n",
      " 5 - Staff \n",
      "\n",
      "time, location, customer, make, work, employee, store, manager, rude, want, ask, order, drive, know, sandwich\n",
      "\n",
      " 6 - Burger Joint \n",
      "\n",
      "burger, fry, cheese, bun, patty, onion, bacon, dry, order, beer, cooked, cold, medium, guy, ring\n",
      "\n",
      " 7 - Service \n",
      "\n",
      "service, bad, horrible, slow, customer, terrible, poor, rude, great, staff, experience, awful, mediocre, quality, restaurant\n",
      "\n",
      " 8 - Seafood \n",
      "\n",
      "buffet, price, sushi, crab, las_vegas, selection, quality, bellagio, dessert, leg, worth, dinner, lunch, money, seafood\n",
      "\n",
      " 9 - Sushi \n",
      "\n",
      "place, like, try, look, price, taste, review, restaurant, great, think, sushi, star, nice, know, thing\n",
      "\n",
      " 10 - Mexican Food \n",
      "\n",
      "taco, fish, burrito, salsa, chip, mexican, bean, bell, tortilla, cold, guacamole, meat, margarita, cheese, rice\n"
     ]
    }
   ],
   "source": [
    "display_topics(neg_nmf, neg_vectorizer.get_feature_names(), 15, topic_names* = neg_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I decided to change things up and zoom in on specific quality metrics like wait time and service, rather than keeping the types of restaurant separate.  This method may gave more insight.**\n",
    "\n",
    "**To do this, I added more stopwords to eliminate any indictation of what type of restaurant it is.  That way, the NMF model will no longer cluster around those types of words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T00:22:41.086479Z",
     "start_time": "2020-01-09T00:22:41.075241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>food</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>1</td>\n",
       "      <td>really one of dirtiest place to eat not sure h...</td>\n",
       "      <td>[Bars, Pubs, Nightlife, Tapas Bars, Restaurants]</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>1</td>\n",
       "      <td>terrible place to eat and or drink waitress be...</td>\n",
       "      <td>[Bars, Pubs, Nightlife, Tapas Bars, Restaurants]</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eU_713ec6fTGNO4BegRaww</td>\n",
       "      <td>1</td>\n",
       "      <td>oh this place i want to like it i really do i ...</td>\n",
       "      <td>[Restaurants, Italian, Pizza]</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eU_713ec6fTGNO4BegRaww</td>\n",
       "      <td>2</td>\n",
       "      <td>this place be byob which i love and i remember...</td>\n",
       "      <td>[Restaurants, Italian, Pizza]</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eU_713ec6fTGNO4BegRaww</td>\n",
       "      <td>2</td>\n",
       "      <td>we use to love come to this restaurant but i m...</td>\n",
       "      <td>[Restaurants, Italian, Pizza]</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  stars  \\\n",
       "0  ikCg8xy5JIg_NGPx-MSIDA      1   \n",
       "1  ikCg8xy5JIg_NGPx-MSIDA      1   \n",
       "2  eU_713ec6fTGNO4BegRaww      1   \n",
       "3  eU_713ec6fTGNO4BegRaww      2   \n",
       "4  eU_713ec6fTGNO4BegRaww      2   \n",
       "\n",
       "                                                text  \\\n",
       "0  really one of dirtiest place to eat not sure h...   \n",
       "1  terrible place to eat and or drink waitress be...   \n",
       "2  oh this place i want to like it i really do i ...   \n",
       "3  this place be byob which i love and i remember...   \n",
       "4  we use to love come to this restaurant but i m...   \n",
       "\n",
       "                                         categories        city  food language  \n",
       "0  [Bars, Pubs, Nightlife, Tapas Bars, Restaurants]     Calgary  True       en  \n",
       "1  [Bars, Pubs, Nightlife, Tapas Bars, Restaurants]     Calgary  True       en  \n",
       "2                     [Restaurants, Italian, Pizza]  Pittsburgh  True       en  \n",
       "3                     [Restaurants, Italian, Pizza]  Pittsburgh  True       en  \n",
       "4                     [Restaurants, Italian, Pizza]  Pittsburgh  True       en  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T16:57:17.142186Z",
     "start_time": "2020-01-09T16:57:16.967068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'about', 'above', 'absolutely', 'across']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more stop words here\n",
    "add_stop_words = ['las','la','tony','ive','say','really','eat','friend','im','cup',\n",
    "                  'good','food','definitely','love','place','las_vegas','recommend',\n",
    "                  'great','service','dish', 'cooky', 'guy', 'want', 'town', 'best',\n",
    "                  'probably','like','morning','spot', 'wine', 'bar', 'chip', 'fish', \n",
    "                  'burrito', 'tortilla', 'favorite', 'absolutely', 'amaze', 'come', \n",
    "                  'try', 'menu', 'look', 'sure', 'lunch', 'chicken', 'pizza', 'crust', \n",
    "                  'cheese', 'topping', 'wing', 'sauce', 'salad', 'slice', 'bread', \n",
    "                  'garlic', 'fry', 'burger', 'coffee', 'egg', 'taco', 'salsa', 'mexican', \n",
    "                  'beer', 'night', 'breakfast', 'sandwich', 'sausage', 'potato', 'toast', \n",
    "                  'bacon', 'pretty', 'husband', 'enjoy', 'meal', 'highly', 'beautiful', \n",
    "                  'cocktail', 'happy', 'hour', 'tea', 'cool', 'special', 'sweet', 'shrimp', \n",
    "                  'rice', 'family', 'visit', 'home', 'know', 'brisket', 'margarita', 'cool', \n",
    "                  'thing', 'sushi', 'meat', 'tasty', 'chocolate', 'strawberry', 'cake', \n",
    "                  'waffle', 'butter', 'latte', 'weve', 'star', 'month', 'wife','way', 'bit',\n",
    "                  'ice', 'cream', 'shop','week', 'couple', 'ill', 'make', 'drink', 'perfect',\n",
    "                  'impressed', 'steak', 'dinner', 'lot', 'table', 'excellent', 'thank', 'day',\n",
    "                  'usually', 'super', 'point', 'year', 'lettuce','bartender','bbq', 'hostess',\n",
    "                  'sat','today']\n",
    "\n",
    "# Join's the stop words above to the standard English list\n",
    "stop_words = stop_words.union(add_stop_words)\n",
    "\n",
    "# Display the first five alpabetically\n",
    "list(sorted(stop_words))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I added n_grams of 1,3 instead of just 1 here.  This means the vectorizer will count all 1, 2, and 3-word combinations.  This vastly increases the feature space and takes longer to run, but it gives more insight in this particular case because some words do belong together as a result of their meaning in context.**\n",
    "\n",
    "**I'll now apply the vectorization and topic modeling to the subsets with the updated stop words and adjusted hyperparameters.  I found setting n_components to 5 in this case worked well.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T17:17:05.705997Z",
     "start_time": "2020-01-09T17:16:52.288769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Positive subset vectorization\n",
    "pos_vectorizer = TfidfVectorizer(ngram_range = (1,3), stop_words = stop_words, min_df = .01)\n",
    "pos_doc_word = pos_vectorizer.fit_transform(pos_review_df['text'])\n",
    "pos_doc_word_df = pd.DataFrame(pos_doc_word.toarray(), columns = pos_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T17:17:28.664386Z",
     "start_time": "2020-01-09T17:17:28.062495Z"
    }
   },
   "outputs": [],
   "source": [
    "# NMF model with 5 topics\n",
    "pos_nmf = NMF(n_components = 5)\n",
    "pos_doc_topic = pos_nmf.fit_transform(pos_doc_word)\n",
    "pos_doc_topic_df = pd.DataFrame(pos_doc_topic.round(5),\n",
    "                                index = pos_review_df.text.apply(lambda x: x[:100]),\n",
    "                                columns = range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T18:54:52.334708Z",
     "start_time": "2020-01-09T18:54:47.084624Z"
    }
   },
   "outputs": [],
   "source": [
    "# Negative subset vectorization\n",
    "neg_vectorizer = TfidfVectorizer(ngram_range = (1,3), stop_words = stop_words, min_df = .01)\n",
    "neg_doc_word = neg_vectorizer.fit_transform(neg_review_df['text'])\n",
    "neg_doc_word_df = pd.DataFrame(neg_doc_word.toarray(), columns = neg_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T18:55:15.013992Z",
     "start_time": "2020-01-09T18:55:14.430985Z"
    }
   },
   "outputs": [],
   "source": [
    "# NMF model with 5 topics\n",
    "neg_nmf = NMF(n_components = 5)\n",
    "neg_doc_topic = neg_nmf.fit_transform(neg_doc_word)\n",
    "neg_doc_topic_df = pd.DataFrame(neg_doc_topic.round(5),\n",
    "                                index = neg_review_df.text.apply(lambda x: x[:100]),\n",
    "                                columns = range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T17:25:07.148748Z",
     "start_time": "2020-01-09T17:25:07.141533Z"
    },
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic:  0\n",
      "restaurant, nice, price, little, taste, flavor, fresh, people, small, area, experience, portion, right, worth, serve\n",
      "\n",
      "Topic:  1\n",
      "staff, friendly, staff friendly, friendly staff, atmosphere, clean, helpful, awesome, nice, fast, location, attentive, quick, wait staff, owner\n",
      "\n",
      "Topic:  2\n",
      "time, long, wait, awesome, server, long time, experience, second, fun, busy, twice, stop, disappointed, customer, people\n",
      "\n",
      "Topic:  3\n",
      "order, wait, minute, delivery, hot, spicy, roll, fast, line, thai, beef, ask, arrive, decide, long\n",
      "\n",
      "Topic:  4\n",
      "delicious, fresh, soup, dessert, yummy, wonderful, roll, spicy, fantastic, perfectly, flavorful, authentic, flavor, homemade, hot\n"
     ]
    }
   ],
   "source": [
    "display_topics(pos_nmf, pos_vectorizer.get_feature_names(), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T18:55:35.068256Z",
     "start_time": "2020-01-09T18:55:35.062970Z"
    },
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic:  0\n",
      "ask, customer, bad, manager, restaurant, server, rude, experience, told, walk, waitress, people, work, staff, need\n",
      "\n",
      "Topic:  1\n",
      "taste, price, buffet, quality, flavor, restaurant, bland, dry, bad, small, fresh, ok, little, disappointed, nice\n",
      "\n",
      "Topic:  2\n",
      "order, wrong, delivery, order order, ask, order wrong, deliver, receive, time order, online, pick, told, min, mess, piece\n",
      "\n",
      "Topic:  3\n",
      "wait, minute, wait minute, seat, long, line, finally, people, minute wait, min, walk, busy, minute order, arrive, server\n",
      "\n",
      "Topic:  4\n",
      "time, location, waste, drive, time time, long, waste time, second, second time, close, slow, long time, time order, open, money\n"
     ]
    }
   ],
   "source": [
    "display_topics(neg_nmf, neg_vectorizer.get_feature_names(), 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can see here that clusters have clear topics.  I'll know label the topics by creating a list of topic names and adding it as an argument to the display_topics() function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T20:53:30.483287Z",
     "start_time": "2020-01-09T20:53:30.480802Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_topic_names = ['Experience','Staff','Wait Time','Time','Atmosphere']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T20:53:30.814203Z",
     "start_time": "2020-01-09T20:53:30.811495Z"
    }
   },
   "outputs": [],
   "source": [
    "neg_topic_names = ['Staff','Food Quality','Order Accuracy','Wait Time','Order Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T20:55:56.346949Z",
     "start_time": "2020-01-09T20:55:56.339364Z"
    },
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 - Experience \n",
      "\n",
      "restaurant, nice, price, little, taste, flavor, fresh, people, small, area, experience, portion, right, worth, serve\n",
      "\n",
      " 2 - Staff \n",
      "\n",
      "staff, friendly, staff friendly, friendly staff, atmosphere, clean, helpful, awesome, nice, fast, location, attentive, quick, wait staff, owner\n",
      "\n",
      " 3 - Wait Time \n",
      "\n",
      "time, long, wait, awesome, server, long time, experience, second, fun, busy, twice, stop, disappointed, customer, people\n",
      "\n",
      " 4 - Time \n",
      "\n",
      "order, wait, minute, delivery, hot, spicy, roll, fast, line, thai, beef, ask, arrive, decide, long\n",
      "\n",
      " 5 - Atmosphere \n",
      "\n",
      "delicious, fresh, soup, dessert, yummy, wonderful, roll, spicy, fantastic, perfectly, flavorful, authentic, flavor, homemade, hot\n"
     ]
    }
   ],
   "source": [
    "display_topics(pos_nmf, pos_vectorizer.get_feature_names(), 15, topic_names = pos_topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T20:53:31.930317Z",
     "start_time": "2020-01-09T20:53:31.924156Z"
    },
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 - Staff \n",
      "\n",
      "ask, customer, bad, manager, restaurant, server, rude, experience, told, walk, waitress, people, work, staff, need\n",
      "\n",
      " 2 - Food Quality \n",
      "\n",
      "taste, price, buffet, quality, flavor, restaurant, bland, dry, bad, small, fresh, ok, little, disappointed, nice\n",
      "\n",
      " 3 - Order Accuracy \n",
      "\n",
      "order, wrong, delivery, order order, ask, order wrong, deliver, receive, time order, online, pick, told, min, mess, piece\n",
      "\n",
      " 4 - Wait Time \n",
      "\n",
      "wait, minute, wait minute, seat, long, line, finally, people, minute wait, min, walk, busy, minute order, arrive, server\n",
      "\n",
      " 5 - Order Time \n",
      "\n",
      "time, location, waste, drive, time time, long, waste time, second, second time, close, slow, long time, time order, open, money\n"
     ]
    }
   ],
   "source": [
    "display_topics(neg_nmf, neg_vectorizer.get_feature_names(), 15, topic_names = neg_topic_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the model results above, it becomes apparent the staff attitude, food quality, and wait time are big drivers of negative sentiment.  Price, food quality, and friendly, competent staff seems to drive the ratings up.**\n",
    "\n",
    "**Since this is such a large dataset, there is a lot more to explore.  For example, this subset mostly covers Las Vegas.  It would be very interesting to see how the metrics differ from city to city.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
